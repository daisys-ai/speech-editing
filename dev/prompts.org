* Setup

In this folder you will find an HTML/JS-only static page that gives a nice
interface for editing the timings of words in a sentence.

You can drag the edges of words, and if you click on a word, you see the
individual phonemes.

I'd like you to do a few initial improvements, and then make some important
changes. Initial improvements:

1. Can you print out the durations of all phonemes in console.log as I move the
   handles around?  I want to see an array of [phoneme, duration] pairs like
   this: [["k", 3], ["w", 2], ["i", 1], ["k": 3]] (for the word "quick", just an
   example but you should handle the whole sentence).  I want this printing to
   come from a callback on duration changes that I can hook into later for a
   different purpose.
2. Can you add the ability to insert "silence" as a word, if I click between the
   words?  You'll need some sort of subtle icon for this, and a way of tracking
   in the code that there is silence there. Silence blocks should just be
   treated as words. If needed, you can represent them in the text with a
   self-closing "<break/>" tag.
3. Back this thing up with an extremely simple server, perhaps using FastAPI.
   Ideally I want the app to be hostable as a static page but for development it
   can be useful to be serving it, and I may have the need for an endpoint or
   two.

Now for the important changes:

1. Add in the top corner a login button that gives a username and password
   field.  The password field should have masked text, and auto-fill between
   sessions using cookies.  No need to show the fields if the user is already
   logged in, you can just indicate that, and show a logout icon.
2. I want you do add support for the Daisys API.  You can find full instructions
   here: https://daisys-ai.github.io/daisys-api-python/daisys-api-doc.txt
3. What I'd like you to use the API for is: for login, and doing so, save the
   accesss token in a local storage or cookie so that the user remains logged in
   unless he logs out.
4. For text to voice. There is a sentence there already, and when the user
   clicks "Preview timing" I'd like you to use the service to perform TTS using
   /take/generate, get the audio, and play it back. You can have an adequate
   waiting spinner. For a voice, please choose a default voice or create one,
   but it has to be for the "infilling-en" model.  I'd like you to do all of
   this in JavaScript on the client side.  Server is there only for static
   serving of the interface.
5. In fact it should not show the word timings at all until it is able to
   retrieve them from the TakeResponse object. (I will add instructions on how
   to do this later, for now assume all words are composed of arbitrary phonemes
   composed of their letters, and timings are some random small integer.)
   Therefore we should not see the duration editing interface until the first
   preview has occurred.  And we should not see preview button until the user
   has logged in.
6. Each preview should be kept in a history and it should be possible to jump
   back to the audio and durations associated with some item in that history.
   Please make a widget to track historical clicks of the play button and offer
   a delete button for the items.  This can all go into local storage, so you
   should also have "folders" per sentence.
7. By the way that means that after the sentence is established, the user should
   not be able to edit it, so the input dialog should be visually disabled.  You
   should organize the history hierarchically so that I can see previous
   sessions and then drill down into previous states (durations and audio
   examples) from those sessions.

* Refinements

After logging in, the modal disappeared but the login button was still there and
no Preview button appeared, so I couldn't do anything else.

Okay but I need an actual access token for TTS to work. Can you add
documentation on how to switch modes to the README?  Also you should
differentiate between the URL for the daisys API, which I do want to override,
and the URL for authentication.  Please support both DAISYS_API_URL and
DAISYS_AUTH_URL as environment variables.  Use an env file with commented out
lines for each configuration.

Login appears to work, according to console messages, but after login I do not
see the preview button and now it is gone even if I refresh.

Progress, login works and preview almost works. I made some edits so that it
successfully generates a voice. Now it's failing to generate a take, but that's
because the JSON is incorrect. Please refer to the Daisys documentation on what
input to get /takes/generate.

Almost there but you are missing the voice_id field.  Please adjust the code to
determine or generate the voice immediately after login, so that everything is
ready to just create a take on demand.

Almost working, but fetching the audio is incorrect. Please process response
from /takes/generate, poll for 'ready' status, and then request the audio using
the /wav URL, as indicated in the Daisys documentation.

#+begin_quote
One thing to watch for in the /wav endpoint. If it is a redirect, please strip
the Authorization header when loading the new location.
#+end_quote

At this stage it's working fine for previews.  Now to work on regeneration.

* Regeneration

The version of the API you are using supports a new endpoint in the Daisys API
that is not documented.  I will tell you how it works and I want you to use it.

For a given sentence, the first time you generate, you should use the
/takes/generate endpoint just like before.  I would like you to remember the
take_id of this first sentence and we will now re-use it.

The second time you generate, I would like you to use the new endpoint
/takes/regenerate.  POST requests to this endpoint are similar to the /generate
endpoint, but take some new fields:

edit_take_id: Optional[str] = None
text_to_edit: Optional[list[Union[tuple[int, int], str]]] = None
phoneme_durations: Optional[list[list[list[tuple[str, int]]]]] = None # sentence, word, (phoneme, duration)

The edit_take_id is where you should put the take_id from the first generate
command.

The text_to_edit is the sequence of words within the sentence for which
durations have been edited.  You will need to calculate this in the UI.  It's
probably better not to track it but rather to just compare durations with the
original output from the first generation.  Maybe to confirm to the user what
they are doing, you can colour the boxes for words that have been edited in a
slightly different shade.  Each item of the outermost list is a sentence, so if
we're just editing one sentence, it should be a one-item list. For example, if
the original text was,

"Hi there buddy.  How are you?"

and you edited "there buddy", then text_to_edit would be either ["there buddy"]
or [[1, 2]] to indicate words 1 and 2 of the first sentence.  If you edited "How
are" then it would be ["", "How are"] or [[], [0, 1]].

For phoneme_durations, this is where the phonemes and their edited durations
will go.  It is a list of sentences. Each sentence is a list of words. Each word
is a list of tuples which are two items: the phoneme (string) and the duration
(integer) in number of frames.

An example of a response (once the take is 'ready') after asking /takes/generate
to synthesize the sentence "Hello there, I am Daisys!" is:

{"text":"Hello there, I am Daisys!","override_language":null,"style":null,"prosody":{"pitch":2,"pace":-3,"expression":10},"is_blocked":false,"status_webhook":null,"done_webhook":null,"user_data":null,"voice_id":"v01jz4za2jby72gmft9gj3bx5z8","take_id":"t01jz4zackwv2263wmch9dfrzas","status":"ready","timestamp_ms":1751439979132,"info":{"duration":98816,"audio_rate":44100,"normalized_text":["Hello there, I am Daisys!"],"phoneme_durations":[[[["SIL",5],["h",2],["ə",4],["l",8],["oʊ",27]],[["ð",4],["ɛɹ",28],["SIL",30]],[["aɪ",5]],[["æ",3],["m",7]],[["d",7],["eɪ",10],["s",11],["ɪ",12],["s",20],["SIL",10]]]]}}

Now, given this information, you have the durations of each phoneme composing
each word.  I want you to make the following updates to the UI:

1. The word box widths should reflect the total duration of each word, and in
   the phoneme editing view, the boxes should reflect the duration of each phoneme.
2. When phonemes or words are edited, this should be recorded, and the colors of
   the boxes should be slightly changed to reflect that they have been edited.
   I suggest doing this statelessly: do not track edits, but rather just always
   compare the current durations with the known durations from the original
   take. That way if a word is edited such that its phonemes are back to their
   original durations, it will be displayed as unedited, but if any phoneme in a
   word has a different duration, it and its word will be displayed as edited.
3. When the user clicks preview, the new preview added to the history should be
   generated by calling /takes/regeneration.  Provide the original take_id,
   provide the longest span of text that was edited in text_to_edit, and provide
   new durations in phoneme_durations.  Otherwise provide the same text and
   voice as the original take.
4. Add three sliders to the interface called "pitch", "pace", and "expression".
   According to the Daisys documentation these take values between -10 and 10.
   These will control the prosody for the original take.  On subsequent
   regenerations, grey out "pace" since that cannot be controlled, but provide
   the prosody with new values for "pitch" and "expression" if they have been
   changed.

** Refining

Some comments:

1. The expression default value seems to not be correct, I have to move the knob
   before the number reflects its position correctly. Make sure to initialize
   the sliders at 0 by default, or position them how they were last time, using
   local storage.
2. Next to the preview button it would be nice to have a "Play again" button
   that doesn't generate again but just plays the last sample that was
   generated.
3. The widths of the word and phoneme boxes do not seem to reflect what is
   returned in phoneme_durations, they are all the same instead of varying for
   each phoneme and word.  Please choose a minimum size and use that as a
   multiplier for the shortest phoneme duration, keep everything proportional to
   that.

** More refining

1. The word and phoneme boxes always have the "reset" button visible, and when I
   click it, they go to some "standard" length.  The "reset" button should set
   them back to the length of the original take instead.
2. When dragging the edge of a box, it doesn't "let go" when I release the mouse button.
3. The "plus" button which adds silence is a good idea, but it should add it
   after the currently selected word.
4. In the request, even though the "pace" slider is not enabled, "pace" should
   still be provided in the prosody specification of the regenerate request.
   All 3 fields, "pitch", "pace", and "expression", are required.
5. The text you are providing in text_to_edit is the full sentence, but it
   should be just the word span of the part of the sentence that has been
   edited.

Further:

1. Can you change the text of "Preview timing" to "Regenerate" after the first
   generation?  This would clarify the meaning of the button.
2. In the regenerate request, you are only supplying the edited phonemes.  You
   need to supply the full phoneme_durations that you got from the original
   response, just with some duration values that may be different than before.
3. Let's fix up the handling of silence a bit.  Many times the generated output
   already contains some SIL tokens.  In the phoneme_durations field, these are
   treated as part of the word they are next to, and this is correct.  However,
   visually it would be nice to "see" them as separate words.  Can you show them
   as such if they are there, but still maintain them linked to the words they
   belong in?  It would also be nice to not need or at least not see these
   "<break/>" tags even though I indicated it could be useful, I think it
   complicates things.
4. By the way can you remove the printing of the access token to the console?
   And please do not use localstorage for the tokens, only session storage,
   which gets cleared when the tab is closed.  If the access token stops
   working, ask for a login again, and also automatically refresh the login
   every 50 minutes.

Looking nice but some problems:

I still have problems with dragging and the mouse not "letting go", and also
in the console I see this error: Uncaught ReferenceError: newDuration is 
  not defined
      addEventListeners http://localhost:8001/js/app.js:601
      addEventListeners http://localhost:8001/js/app.js:572
      init http://localhost:8001/js/app.js:1638
      EventListener.handleEvent* http://localhost:8001/js/app.js:1671

** More refining

1. Can I have a "clear all" button for the history, which slides out a
   confirm checkmark or cancel button before taking action?
2. On clicking generate for the first time, a few words are
   already marked as edited. I tried clearing my browser storage thinking it was
   just leftover state but it still does it, can you look for a reason?
   Possibly linked to SIL tokens.  To be clear, I only want words to be marked
   as edited if the word length has changed, or a particular phoneme length has
   changed.
3. I'm assuming that if the user edits the whole word, all phoneme lengths
   change proportionally, so the final phoneme lengths are the combination of
   the word length and phoneme proportions. Please check if this is indeed how
   it works, because visually it feels like that is how it should work.
4. The "restore durations" button in the history does not work.
5. The text_to_edit has again become the whole sentence instead of just the
   the edited words, please fix.

Again,

1. Works much better but I am still not sure why by default a word is marked as
   edited immediately after the initial generation.
2. Sometimes I still get errors if I edit a phoneme duration.  The error seems
   to be that the requested phoneme durations do not perfectly match the old
   ones, please see this example that I extracted from the backend logs, after
   adjusting the length of the "o" in the word "dog", you can see that it
   added and dropped some phonemes compared to the original phoneme_durations:

After a bit more fixing above, so close now, but..

When I edit one word it works, but when I edit 2 words, I see that text_to_edit
is incorrect.  I see though that in this case text_to_edit is incorrect, as it
is listening two parts to edit, and text_to_edit is length 2.

For one sentence, text_to_edit should always be a list of length 1, it is length
2 if there are two sentences, etc.  Inside text_to_edit, there should be a
string consistent of all the words to edit.  So if I modified "find" and "at" in
"please find a seat at the table", then text_to_edit should be ["find a seat at"].

** Working well! Refinements.

Works great. Now some refinements.

1. To the far right of the "Play again" button, can I have a "Start again"
   button that resets the state completely (without erasing history)?  That is,
   it should clear the editing area, let you edit the text and enable the Pace
   selection again, etc.
2. The "Restore duration" buttons in the history do not work, they just put
   durations to some kind of default instead of loading up the settings that
   were used for that generation or regeneration.  I want it to restore things
   exactly as they were, including the original take information such as what
   the text was, etc.
3. Dragging the word boundary to stretch the whole word seems to have a limited
   length. Can you increase this limit?
4. Can you make it so that I can manipulate the length of SIL words?
5. Can you get rid of the "faster -- slower" slider?
6. Change the page title from "Word Duration" to "DAISYS speech editing
   demo", adjust font size if you need to fit that on the page.  Perhaps put
   DAISYS in a smaller font above, then "speech editing" bigger, and "demo"
   smaller again below that.

** Now thinking about hosting

Since this is pretty much a static single page app, can you add a CI/CD github
step that pushes it to the gh-pages branch?

Okay finally figured that out on github and didn't need Claude's help with it,
so had to undo some things.

** More refinement

Can you make it so that when a voice fails to be generated, or any other errors,
that a message gets added to the screen in a small font below where it says
"Voice setup required." instead of using an alert()?  Please avoid alert().
